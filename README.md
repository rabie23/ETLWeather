Das ist ein fantastischer Abschluss! Im Screenshot von **DBeaver** sieht man ganz deutlich die Tabelle `weather_data` mit echten Werten fÃ¼r Temperatur (8,9 und 8,6 Grad), Windgeschwindigkeit und Zeitstempel. Damit ist der Beweis erbracht: Deine ETL-Pipeline funktioniert von der API bis in die Datenbank einwandfrei.

Hier ist die professionelle, deutsche README fÃ¼r dein GitHub-Repository, die genau auf dein fertiges Projekt zugeschnitten ist:

---

# ğŸŒ¦ï¸ Berlin Weather ETL Pipeline

Dieses Projekt ist eine automatisierte **ETL-Pipeline** (Extract, Transform, Load), die mit **Apache Airflow** und der **Astro CLI** realisiert wurde. Es ruft Echtzeit-Wetterdaten ab, bereitet sie auf und speichert sie in einer PostgreSQL-Datenbank.

## ğŸš€ Projekt-Ãœbersicht

Die Pipeline fÃ¼hrt folgende Schritte vollautomatisch aus:

1. **Extract**: Abruf aktueller Wetterdaten fÃ¼r Berlin Ã¼ber die **Open-Meteo API**.
2. **Transform**: Aufbereitung der Rohdaten (Temperatur, Windgeschwindigkeit, Wettercode) mittels Python.
3. **Load**: Speicherung der sauberen Daten in einer **PostgreSQL** Datenbank.

---

## ğŸ› ï¸ Technologie-Stack

* **Orchestrierung**: Apache Airflow (Astronomer Runtime)
* **Sprache**: Python 3.x
* **Datenbank**: PostgreSQL (Docker-Container)
* **Monitoring**: DBeaver Lite (fÃ¼r SQL-Abfragen)
* **Infrastruktur**: Docker & Astro CLI

---

## ğŸ“‚ Projektinhalt

Das Projekt wurde mit der Astronomer CLI generiert und angepasst:

* **`dags/etlweather.py`**: EnthÃ¤lt die DAG-Logik und die Task-Definitionen (`@task`).
* **`requirements.txt`**: Installiert die notwendigen Provider fÃ¼r HTTP und Postgres.
* **`docker-compose.yml`**: Konfiguration der lokalen Infrastruktur (Datenbank & Airflow-Services).

---

## ğŸ’» Lokale AusfÃ¼hrung & Nutzung

1. **Infrastruktur starten**:
```bash
astro dev start

```


Dies startet fÃ¼nf Docker-Container: Postgres (Metadaten-DB), Scheduler, API-Server (UI), Triggerer und den DAG-Prozessor.
2. **Airflow UI**: Erreichbar unter `http://localhost:8080`.
3. **Daten prÃ¼fen**: Die Ergebnisse kÃ¶nnen direkt in einem SQL-Tool wie **DBeaver** Ã¼ber `localhost:5432/postgres` (User: `postgres` / Pass: `postgres`) mit folgendem Befehl abgefragt werden:
```sql
SELECT * FROM weather_data;

```



---
<img width="1907" height="853" alt="image" src="https://github.com/user-attachments/assets/244cd098-bab1-43e2-8c1d-7c2086117000" />


## ğŸ‘¤ Kontakt & Autor

**Rabie**
GitHub: [github.com/rabie23](https://github.com/rabie23)

---

### Was du jetzt tun kannst:

1. Erstelle die Datei `README.md` in deinem VS Code Ordner.
2. Kopiere diesen Text hinein.
3. FÃ¼hre die `git`-Befehle von vorhin aus, um alles auf GitHub zu laden.

Soll ich dir noch helfen, einen kleinen "Azure"-Abschnitt hinzuzufÃ¼gen, falls du planst, die DB spÃ¤ter in dein Azure-Konto zu verschieben?
